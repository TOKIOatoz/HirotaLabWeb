<!DOCTYPE html>
<html lang="ja">
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title>Hirota's&nbsp;Lab&nbsp;広田研究室</title>
        <meta name="description" content="電気通信大学広田研究室のWebサイトです．主にVR環境での操作，力触覚提示のデバイスとアルゴリズム，五感情報通信等の研究をしています．その他，認知心理学やEmbodiment，ＣＧ，ARの研究テーマを志望する学生も受け入れています．">
        <meta property="og:url" content="http://www.hirota-lab.sumomo.ne.jp/">
        <meta property="og:title" content="Hirota's Lab">
        <meta property="og:image" content="D:/ドキュメント/GitClone/HirotaLabWeb/Image/OGPHirotaLab.png"> 
        <link rel="icon" href="D:/ドキュメント/GitClone/HirotaLabWeb/Image/HirohamuIcon64.png" type="image/png">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="D:/ドキュメント/GitClone/HirotaLabWeb/Style/MobileStyle.css" type="text/css" media="(max-width: 859px)">
        <link rel="stylesheet" href="D:/ドキュメント/GitClone/HirotaLabWeb/Style/PCStyle.css" type="text/css" media="(min-width: 860px)">
    </head>
    <body>
        <header>
            <div id="in_header">
                <div class="div_flex">
                    <div id="blank"></div>
                    <div id="title">
                        <span class="title_ja">
                            <strong>
                                対話型システム学講座&nbsp;広田研究室<br>
                            </strong>
                        </span>
                        <a class="title_en" href="D:/ドキュメント/GitClone/HirotaLabWeb/home.html" target="_blank">
                            <strong>
                                Hirota's&nbsp;Lab.
                            </strong>
                        </a>
                    </div>
                    <div id="blank">
                        <div id="blank_in">
                        </div>
                    </div>
                    <div id="content_menu">
                        <div class="content_flexbox_wrap">
                            <div class="div_flex_content">
                                <div class="content">
                                    <a class="content_link" href="D:/ドキュメント/GitClone/HirotaLabWeb/home.html#introduction" target="_blank">
                                        <strong>
                                            Introduction
                                        </strong>
                                    </a>
                                </div>
                                <div class="content">
                                    <a class="content_link" href="D:/ドキュメント/GitClone/HirotaLabWeb/home.html#research" target="_blank">
                                        <span>
                                            <strong>
                                                Research
                                            </strong>
                                        </span>
                                    </a>
                                </div>
                                <div class="content">
                                    <a class="content_link" href="D:/ドキュメント/GitClone/HirotaLabWeb/home.html#member" target="_blank">
                                        <span>
                                            <strong>
                                                Member
                                            </strong>
                                        </span>
                                    </a>
                                </div>
                            </div>
                        </div>
                        <div class="content_flexbox_wrap">
                            <div class="div_flex_content">
                                <div class="content">
                                    <a class="content_link" href="D:/ドキュメント/GitClone/HirotaLabWeb/home.html#lecture" target="_blank">
                                        <span>
                                            <strong>
                                                Lecture
                                            </strong>
                                        </span>
                                    </a>
                                </div>
                                <div class="content">
                                    <a class="content_link" href="D:/ドキュメント/GitClone/HirotaLabWeb/home.html#access" target="_blank">
                                        <span>
                                            <strong>
                                                Access
                                            </strong>
                                        </span>
                                    </a>
                                </div>
                                <div class="content">
                                    <a class="content_link" href="D:/ドキュメント/GitClone/HirotaLabWeb/home.html#link" target="_blank">
                                        <span>
                                            <strong>
                                                Link
                                            </strong>
                                        </span>
                                    </a>
                                </div>
                                <div class="content">
                                    <a class="content_link" href="D:/ドキュメント/GitClone/HirotaLabWeb/home.html#recruit" target="_blank">
                                        <span>
                                            <strong>
                                                Recruit
                                            </strong>
                                        </span>
                                    </a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </header>
        <div id="main">
            <div id="research" class="content_main">
                <a class="content_name" href="D:/ドキュメント/GitClone/HirotaLabWeb/contents/research_detail.html" target="_blank">
                    Research&nbsp;研究&nbsp;一覧
                </a>
                <hr>
                <div class="div_flex_wrap">
                    <div class="other_content_menu">
                        <div class="content_subtitle">
                            研究領域
                        </div>
                        <div class="content_text">
                            <ul>
                                <li>
                                    <a class="list_a" href="#VR_hand_model_and_operation">
                                        VR手モデルと操作
                                    </a>
                                </li>
                                <li>
                                    <a class="list_a" href="#haptic_presentation">
                                        手の触覚提示
                                    </a>
                                </li>
                                <li>
                                    <a class="list_a" href="#VR_object_model">
                                        VR物体モデル
                                    </a>
                                </li>
                                <li>
                                    <a class="list_a" href="#body_sensation_and_self_awareness">
                                        身体感覚と自己認識
                                    </a>
                                </li>
                                <li>
                                    <a class="list_a" href="#emotion_and_affect">
                                        感情と情動
                                    </a>
                                </li>
                                <li>
                                    <a class="list_a" href="#sense_of_walking">
                                        歩行間隔
                                    </a>
                                </li>
                                <li>
                                    <a class="list_a" href="#haptic_interface">
                                        触覚インターフェース
                                    </a>
                                </li>
                                <li>
                                    <a class="list_a" href="#other_research">
                                        その他
                                    </a>
                                </li>
                            </ul>
                        </div>
                    </div>
                    <div class="other_content_menu">
                        <div class="content_subtitle">
                            最近元気なプロジェクト
                        </div>
                        <div class="content_text">
                            <ul>
                                <li>
                                    <a class="list_a" href="#haptic_presentation">
                                        指先に高密度な刺激を提示する圧覚ディスプレイ
                                    </a>
                                </li>
                                <li>
                                    <a class="list_a" href="#body_sensation_and_self_awareness">
                                        VRツイスター
                                    </a>
                                </li>
                                <li>
                                    <a class="list_a" href="https://kaken.nii.ac.jp/ja/grant/KAKENHI-PROJECT-19H05661/">
                                        融合身体VR
                                    </a>
                                </li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div id="VR_hand_model_and_operation" class="content_main">
                <!--コンテンツタイトル-->
                <span class="content_name">
                    VR手モデルと操作
                </span>
                <hr>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        計測に基づく手モデルの構築&nbsp;[2016-]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        手は人によって個人差があります。それぞれのユーザにぴったり合う手モデルを作ることで、個人差による違和感や操作性の問題を軽減することを考えています。外形だけでなく内部の骨の大きさや、関節の回転軸の位置もことなるので、内部を含めた計測が必要です。この研究ではMRIで撮影した画像からモデルを構築する手法を検討しています。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/mri_hand1.jpg" alt="MRI画像">
                            <figcaption>
                                MRI画像
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/mri_hand2.jpg" alt="手モデル">
                            <figcaption>
                                手モデル
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/mri_hand3.jpg" alt="骨の構造">
                            <figcaption>
                                骨の構造
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            広田&nbsp;光一,&nbsp;田川&nbsp;和義,&nbsp;小森&nbsp;優,&nbsp;櫻井&nbsp;翔,&nbsp;野嶋&nbsp;琢也:&nbsp;計測に基づく手のリンクモデルの構築;&nbsp;日本VR学会&nbsp;ハプティックス研究会&nbsp;第22回&nbsp;予稿集,&nbsp;No.6,&nbsp;2019
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        微小運動によるVR手の操作&nbsp;[2017-2018]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        VR空間内で仮想の手を用いて操作するシステムが開発されている。操作にユーザーの手のひねりや移動、指の屈伸を含む動作を用いるためにカメラや磁気センサを用いてトラッキングするシステムがある。これらは仮想手のパフォーマンスが現実の手を動かすスペースや、ユーザーの手の状態に影響される。本研究では現実の手の微小な動きでも仮想の手を操作可能なシステムの開発を目指している。デバイスは手を置く台とトラッキングのためのleapmotionのみで構成している。手を大きく動かさないので光学センサのオクルージョンの無い配置が可能であり、簡易な設置も実現できるのではないかと考えた。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/TVRhand1.png" alt="写真1">
                            <figcaption>
                                写真1
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/TVRhand2.jpg" alt="写真2">
                            <figcaption>
                                写真2
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/TVRhand3.jpg" alt="写真3">
                            <figcaption>
                                写真3
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            藤岡&nbsp;駿介&nbsp;広田&nbsp;光一&nbsp;野嶋&nbsp;琢也&nbsp;赤羽&nbsp;克仁&nbsp;佐藤&nbsp;誠:&nbsp;主体感によるVR操作性の向上;&nbsp;日本VR学会第22回大会予稿集&nbsp;1C3-04&nbsp;2017
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        柔らかい皮膚をもつ手モデル&nbsp;[2013-2016]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        人の皮膚は変形する。VR環境における手と物体の接触計算においても、手の柔らかさを考慮することで、より現実的なシミュレーションが可能になると期待される。本研究では、皮膚を柔軟体としてモデル化した手モデルを構築し、これを用いた操作を実現した。手モデルは皮膚と骨より構成され、骨は皮膚に対して固定の境界条件を与える。皮膚と物体との接触力の計算にはペナルティ法を用いた。計算処理にGPUを用いることで実時間の操作を可能とした。<br>
                        ※この研究は科研費基盤研究(B)25280072の支援を受けて実施された。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/defhand1.jpg" alt="操作の例">
                            <figcaption>
                                操作の例
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/defhand2.jpg" alt="操作実験環境">
                            <figcaption>
                                操作実験環境
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_video">
                            <video src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/defhand.mp4" controls>
                                <a href="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/defhand.mp4" download>
                                    物体操作
                                </a>
                            </video>
                            <figcaption>
                                物体操作
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Koichi&nbsp;Hirota,&nbsp;Yusuke&nbsp;Ujitoko,&nbsp;Kazuya&nbsp;Kiriyama,&nbsp;Kazuyoshi&nbsp;Tagawa:&nbsp;Object&nbsp;Manipulation&nbsp;by&nbsp;Deformable&nbsp;Hand;&nbsp;Proc.&nbsp;AsiaHaptics&nbsp;2014,&nbsp;LNEE&nbsp;227,&nbsp;145-148,&nbsp;2015
                        </li>
                        <li>
                            Koichi&nbsp;Hirota,&nbsp;Kazuyoshi&nbsp;Tagawa:&nbsp;Interaction&nbsp;with&nbsp;Virtual&nbsp;Object&nbsp;using&nbsp;Deformable&nbsp;Hand;&nbsp;Proc.&nbsp;VR2016,&nbsp;49-56,&nbsp;2016.3
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        手形状の計測手法&nbsp;[2014-2016]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        手の関節角の計測にはグローブ型のセンサが広く使われている。しかし、多くのグローブは手の自由度に比べて自由度が少なく、センサの構造から精度も低いものが多い。本研究では、骨とほぼ剛に接続されている爪の位置姿勢を計測し、これをもとに関節角を推定する手法を開発している。<br>
                        ※この研究は科研費基盤研究(B)25280072の支援を受けて実施された。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/hand_sens.jpg" alt="センサの取り付け">
                            <figcaption>
                                センサの取り付け
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/hand_estim.jpg" alt="推定された手モデル">
                            <figcaption>
                                推定された手モデル
                            </figcaption>
                        </figure>
                    </div>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        物体操作における触力覚情報の聴覚提示&nbsp;[2012-2013]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        手と物体の接触の情報を聴覚によりフィードバックする手法について予備的な検討を行った。接触の位置、接触力の大きさ、接触領域での物体の曲率などを、音程および音色、音の強さ、音の揺らぎ（ビブラート）などに変換して提示するシステムを構築し、手探りによる物体の探索、物体形状の認識、把持操作の３つのタスクのパフォーマンスを評価した。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/oto1.jpg" alt="実験環境">
                            <figcaption>
                                実験環境
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/oto2.jpg" alt="物体形状の認識">
                            <figcaption>
                                物体形状の認識
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_video">
                            <video src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/oto1.mp4" controls>
                                <a href="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/oto1.mp4" download>
                                    位置認識作業
                                </a>
                            </video>
                            <figcaption>
                                位置認識作業
                            </figcaption>
                        </figure>
                        <figure class="other_video">
                            <video src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/oto2.mp4" controls>
                                <a href="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/oto2.mp4" download>
                                    形状弁別作業
                                </a>
                            </video>
                            <figcaption>
                                形状弁別作業
                            </figcaption>
                        </figure>
                        <figure class="other_video">
                            <video src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/oto3.mp4" controls>
                                <a href="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/oto3.mp4" download>
                                    把持作業
                                </a>
                            </video>
                            <figcaption>
                                把持作業
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Xiaoshu&nbsp;Zhou,&nbsp;Koichi&nbsp;Hirota&nbsp;:&nbsp;Auditory&nbsp;Feedback&nbsp;of&nbsp;Contact&nbsp;State&nbsp;during&nbsp;Object&nbsp;Manipulation;&nbsp;Proc.&nbsp;3DUI2013,&nbsp;185-186,&nbsp;2013&nbsp;(poster)
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        巧緻な作業の実現&nbsp;-&nbsp;お手玉を例として&nbsp;[2009-2011]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        巧緻な操作をVR環境で実現することの困難や問題を明らかにするために、お手玉のための操作環境の構築とその分析評価を行った。お手玉はボールを素早い動作で正確に扱う必要がある。シミュレーション精度の改善や、手とボールの接触の音によるフィードバックなどにより、ある程度現実的な操作が可能であることが示された。また、現実のスキルがVR環境においても利用できることが示唆された。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/ote1.jpg" alt="お手玉のためのVR環境">
                            <figcaption>
                                お手玉のためのVR環境
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/ote2.jpg" alt="手とボールの軌跡">
                            <figcaption>
                                手とボールの軌跡
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_video">
                            <video src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/ote1.mp4" controls>
                                <a href="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/ote1.mp4" download>
                                    2ボール(1G)
                                </a>
                            </video>
                            <figcaption>
                                2ボール(1G)
                            </figcaption>
                        </figure>
                        <figure class="other_video">
                            <video src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/ote2.mp4" controls>
                                <a href="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/ote2.mp4" download>
                                    3ボール(0.5G)
                                </a>
                            </video>
                            <figcaption>
                                3ボール(0.5G)
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Minato&nbsp;Mizutori,&nbsp;Koichi&nbsp;Hirota,&nbsp;Yasushi&nbsp;Ikei:&nbsp;Skillful&nbsp;Manipulation&nbsp;of&nbsp;Virtual&nbsp;Objects;&nbsp;Proc.&nbsp;VSMM2012,&nbsp;79-86,&nbsp;2012
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        物体の把持操作&nbsp;[1999-2004]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        干渉応答計算にもとづく物体操作について検討した。ユーザの手指を干渉点の集合として表現し、それぞれの点における接触力を計算する。これらの反作用の総和としての力およびトルクにより物体を運動させることで、物理ベースの操作を実現する。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/manip1.jpg" alt="把持操作">
                            <figcaption>
                                把持操作
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/manip2.jpg" alt="手形状の計測">
                            <figcaption>
                                手形状の計測
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_video">
                            <video src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/manip1.mp4" controls>
                                <a href="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/manip1.mp4" download>
                                    計測
                                </a>
                            </video>
                            <figcaption>
                                計測
                            </figcaption>
                        </figure>
                        <figure class="other_video">
                            <video src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/manip2.mp4" controls>
                                <a href="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/manip2.mp4" download>
                                    力の計算
                                </a>
                            </video>
                            <figcaption>
                                力の計算
                            </figcaption>
                        </figure>
                        <figure class="other_video">
                            <video src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/manip3.mp4" controls>
                                <a href="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/manip3.mp4" download>
                                    ボックスの操作
                                </a>
                            </video>
                            <figcaption>
                                ボックスの操作
                            </figcaption>
                        </figure>
                        <figure class="other_video">
                            <video src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/manip4.mp4" controls>
                                <a href="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchVideo/manip4.mp4" download>
                                    カップの操作
                                </a>
                            </video>
                            <figcaption>
                                カップの操作
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            K.Hirota,&nbsp;M.Hirayama,&nbsp;A.Tanaka,&nbsp;M.Hirose,&nbsp;T.Kaneko:&nbsp;Physically-Based&nbsp;Simulation&nbsp;of&nbsp;Object&nbsp;Manipulation;&nbsp;Proc.&nbsp;ASME&nbsp;DSCD&nbsp;2000&nbsp;(DSC-Vol.69-2),&nbsp;1167-1174,&nbsp;2000.11.
                        </li>
                        <li>
                            K.Hirota,&nbsp;M.Hirose:&nbsp;Dexterous&nbsp;Object&nbsp;Manipulation&nbsp;Based&nbsp;on&nbsp;Collision&nbsp;Response;&nbsp;Proc.&nbsp;IEEE&nbsp;VR&nbsp;2003,&nbsp;232-239,&nbsp;2003.3.
                        </li>
                        <li>
                            K.Hirota,&nbsp;M.Hirayam,&nbsp;A.Tanaka,&nbsp;T.Kaneko:&nbsp;Spatial&nbsp;Constraint&nbsp;Method&nbsp;-&nbsp;A&nbsp;new&nbsp;approach&nbsp;to&nbsp;real-time&nbsp;haptic&nbsp;interaction&nbsp;in&nbsp;virtual&nbsp;environments;&nbsp;Presence,&nbsp;13(3),&nbsp;355-370,&nbsp;2004.
                        </li>
                    </ol>
                </div>
                <br>
            </div>
            <div id="haptic_presentation" class="content_main">
                <!--コンテンツタイトル-->
                <span class="content_name">
                    触覚提示
                </span>
                <hr>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        指先に高密度な刺激を提示する圧覚ディスプレイ&nbsp;[2019- ]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        指先のはらの領域に128点の独立に制御できるアクチュエータを配置しています。個々のアクチュエータはピンを空気圧で押し出すことで力を作用する仕組みです。作用点でのピンの間隔は約1.4mmで指先の触二点閾に近い密度での刺激提示を可能としました。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/taniguchi_hd1.png" alt="デバイスの構造">
                            <figcaption>
                                デバイスの構造
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/taniguchi_hd2.png" alt="実装されたデバイス">
                            <figcaption>
                                実装されたデバイス
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Yusuke&nbsp;Ujitoko,&nbsp;Takaaki&nbsp;Taniguchi,&nbsp;Sho&nbsp;Sakurai,&nbsp;Koichi&nbsp;Hirota:&nbsp;Development&nbsp;of&nbsp;Finger-Mounted&nbsp;High-Density&nbsp;Pin-Array&nbsp;Haptic&nbsp;Display;&nbsp;IEEE&nbsp;Access,&nbsp;8,&nbsp;145107-145114,&nbsp;2020
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        多点ディスプレイによる物体内部の質感表現&nbsp;[2019- ]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        触覚ディスプレイはふつうはぶった表面の質感の表現に使われますが、液状のものなどに指を入れたときの感触など、空間的な性質の表現に応用することも考えられます。この研究では、多点のピンアレイディスプレイを使って、対象物体の性質を表現することを試みています。この結果、すくなくとも「チリチリ」「ツブツブ」「ザラザラ」のような違いをユーザに提示できることが確認されました。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/ota_shitsukan1.jpg" alt="提示手法">
                            <figcaption>
                                提示手法
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/ota_shitsukan2.jpg" alt="認識実験結果">
                            <figcaption>
                                認識実験結果
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Yusuke&nbsp;Ota;&nbsp;Yusuke&nbsp;Ujitoko;&nbsp;Sho&nbsp;Sakurai;&nbsp;Takuya&nbsp;Nojima;&nbsp;Koichi&nbsp;Hirota:&nbsp;Inside&nbsp;Touch:&nbsp;Presentation&nbsp;of&nbsp;Tactile&nbsp;Feeling&nbsp;Inside&nbsp;Virtual&nbsp;Object&nbsp;Using&nbsp;Finger-Mounted&nbsp;Pin-Array&nbsp;Display;&nbsp;IEEE&nbsp;Access,&nbsp;doi:10.1109/ACCESS.2021.3082100,&nbsp;2021.
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        高密度広範囲の手触覚提示&nbsp;[2017-2018]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        本研究では手に対する広範囲、高密度の触力覚提示を可能とする装着型ハプティックデバイス及びそのシステムの開発を行っています。本デバイスは空気圧によって、手に取り付けたピンモジュールを駆動させ、皮膚を圧迫することによって触覚的なフィードバックを行います。ピンの数は128点あり、それぞれの指の関節ごとに、末節に6点、中節に4点、基節に6点となっており、残りは手のひらに配置されています。空気圧による圧迫の強さは、仮想空間内での仮想の手と仮想オブジェクトの接触によって変化し、接触判定による力を電圧に変換することで空気圧を制御しています。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/Tfoot1.jpg" alt="写真1">
                            <figcaption>
                                写真1
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/Tfoot2.jpg" alt="写真2">
                            <figcaption>
                                写真2
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/Tfoot3.jpg" alt="写真3">
                            <figcaption>
                                写真3
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            谷口&nbsp;登章,&nbsp;櫻井&nbsp;翔,&nbsp;野嶋&nbsp;琢也,&nbsp;広田&nbsp;光一:&nbsp;空気圧駆動ピンを用いた多点圧覚提示デバイス;&nbsp;日本VR学会第22回大会予稿集,&nbsp;2D1-04,&nbsp;2017
                        </li>
                        <li>
                            Takaaki&nbsp;Taniguchi,&nbsp;Sho&nbsp;Sakurai,&nbsp;Takuya&nbsp;Nojima,&nbsp;Koichi&nbsp;Hirota:&nbsp;Multi-Point&nbsp;Pressure&nbsp;Sensation&nbsp;Display&nbsp;using&nbsp;Pneumatic&nbsp;Actuators;&nbsp;Proc.&nbsp;EuroHaptics&nbsp;2019,&nbsp;LNCS&nbsp;10894,&nbsp;58-67,&nbsp;2018&nbsp;(poster)
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        手の力触覚の足裏代替位提示&nbsp;[2015- ]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        昨今、VR空間での触覚提示デバイスが数多く開発されている。しかし、その多くは機構や重量などによる手の動きを制約してしまうデバイスがほとんどです。近年は、小型の触覚デバイスも開発されてきていますが、触覚提示は指先に限定されており手全体を用いた触認識ができません。これらの問題を踏まえて、VR空間内で触った時の手の感覚を人間の他の部位に提示するデバイスを制作した。この時に、運動する手と提示する部位の違いにより混乱してしまうと考えられる。そこで、現実の手の運動感覚、他部位の触覚提示、視覚による感覚の統合を行い、触った感覚を理解することができれば、デバイスによって妨げとなっていた手を自由に動かす問題を解決したうえで、手全体に触認識や操作を行うことができるかを検討しています。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/foot1.jpeg" alt="圧覚提示デバイス">
                            <figcaption>
                                圧覚提示デバイス
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/foot2.jpeg" alt="空気アクチュエータ">
                            <figcaption>
                                空気アクチュエータ
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            岡野&nbsp;哲大,&nbsp;広田&nbsp;光一,&nbsp;野嶋&nbsp;琢也:&nbsp;空気圧駆動型デバイスを用いた足裏への触覚提示;&nbsp;日本VR学会研究報告,&nbsp;HDC16,&nbsp;No.11,&nbsp;2015.11.
                        </li>
                        <li>
                            Tetsuhiro&nbsp;Okano,&nbsp;Koichi&nbsp;Hirota,&nbsp;Takuya&nbsp;Nojima,&nbsp;Michiteru&nbsp;Kitazaki,&nbsp;Yasushi&nbsp;Ikei:Haptic&nbsp;Feedback&nbsp;for&nbsp;Foot&nbsp;Sole&nbsp;Using&nbsp;Pneumatic&nbsp;Pressure&nbsp;Device;&nbsp;Proc.ASIAGRAPH2016,&nbsp;3-6,&nbsp;2016.3.
                        </li>
                        <li>
                            Keigo&nbsp;Hiki,&nbsp;Tetsuhiro&nbsp;Okano,&nbsp;Sho&nbsp;Sakurai,&nbsp;Takuya&nbsp;Nojima,&nbsp;Michiteru&nbsp;Kitazaki,&nbsp;Yasushi&nbsp;Ikei,&nbsp;Koichi&nbsp;Hirota:&nbsp;Substitution&nbsp;of&nbsp;hand-object&nbsp;pressure&nbsp;cues&nbsp;with&nbsp;the&nbsp;sole&nbsp;of&nbsp;the&nbsp;foot&nbsp;for&nbsp;haptic&nbsp;presentation&nbsp;using&nbsp;a&nbsp;tactile&nbsp;pin&nbsp;array;&nbsp;Proc.&nbsp;EuroHaptics&nbsp;2018,&nbsp;LNCS&nbsp;10894,&nbsp;239-251,&nbsp;2018
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        力覚提示による触認識&nbsp;[2016-2017]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        操作における触力覚情報の必要性は古くから指摘されている。触力覚が操作に果たす役割は、把持の認識、運動の拘束、作用力の認識など様々であるが、本研究では、対象の認識に着目した。すなわち、触力覚を通して対象の形状やそれにまつわる属性を取得することに着目した。形状の認識には触覚情報の面的な広がりが重要であると考えられる。SPIDAR-Uによる指先5点への力覚提示は、従来の道具型デバイスによるペン先への力提示に比べて空間的な広がりを持つことから、上述の目的に効果があると期待される。本研究では、形状認識の特性の評価を試みている。<br>
                        ※この研究は東工大の佐藤・赤羽研究室との共同研究です。<br>
                        ※この研究は科研費挑戦的萌芽研究JP16K12474の支援を受けて実施されている。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/spidar-exp1.jpg" alt="実物体の提示">
                            <figcaption>
                                実物体の提示
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/spidar-exp2.jpg" alt="VR物体の提示">
                            <figcaption>
                                VR物体の提示
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div>
                        <h4>
                            Video
                        </h4>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/spidar-manip.mp4" download>
                                物体形状の提示
                            </a>
                        </div>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            藤岡,&nbsp;広田,&nbsp;野嶋,&nbsp;赤羽,&nbsp;佐藤:&nbsp;力覚提示システムを用いた触認識に関する評価;&nbsp;VR学会第21大会予稿集,&nbsp;32A-03,&nbsp;2016.9.
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        SPIDAR-Uの開発&nbsp;[2015-2017]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        右手の５指への力覚提示を実現する力覚デバイスSPIDAR-Uを開発した。手指の姿勢を磁気センサにより計測することを前提に、フレームを磁界への影響が小さい木材で、機構部品の多くをプラスティックで構成し、モータなどを作業領域から遠ざけて配置している。物体との接触に伴う力は、研究室で開発された変形手モデルをベースに柔らかさの非線形性を近似的に取り入れた計算手法を導入した。これにより、主観的には操作性が向上したと感じている。現在、システムの定量的評価について検討している。<br>
                        ※この研究は東工大の佐藤・赤羽研究室との共同研究です。<br>
                        ※この研究は科研費基盤研究(B)JP25280072の支援を受けて実施された。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/spidar-u.png" alt="SPIDAR-U">
                            <figcaption>
                                SPIDAR-U
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/col-force.jpg" alt="接触力の計算">
                            <figcaption>
                                接触力の計算
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            内山&nbsp;貴雄,&nbsp;赤羽&nbsp;克仁,&nbsp;佐藤&nbsp;誠,&nbsp;広田&nbsp;光一:&nbsp;磁気的干渉の少ない多指力覚提示装置の提案;&nbsp;日本VR学会研究報告,&nbsp;HDC17,&nbsp;No.7,&nbsp;2016
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        触力覚の対側提示&nbsp;[2014-2015]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        触力覚デバイスの実装の困難の原因の一つは、手のもつ複雑な形状と多くの自由度にある。これにより自由度の高いデバイスは装着が手の動きを妨げることになる。もし手を使う操作の際に生じる触力覚情報を別の部位に提示することができて、この触力覚情報と操作にともなう運動の感覚と統合して解釈することができれば、デバイスの実装を容易にすることができる。本研究ではそのための予備的な検討として、反対側の手に触力覚を提示した場合の操作性を評価している。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/v-device.jpg" alt="振動デバイス">
                            <figcaption>
                                振動デバイス
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/p-device.jpg" alt="圧覚デバイス">
                            <figcaption>
                                圧覚デバイス
                            </figcaption>
                        </figure>
                    </div>
                </div>
                <br>
            </div>
            <div id="VR_object_model" class="content_main">
                <!--コンテンツタイトル-->
                <span class="content_name">
                    VR物体モデル
                </span>
                <hr>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        仮想粘土シミュレーション&nbsp;[2017- ]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        近年、力覚提示（ハプティクス）とその入力装置の進化により、細かい動作を必要とする場合であっても、まるで実際に体験しているかのように仮想体験を行うことが出来るようになってきています。そこで、陶芸のような粘土物でモノを造形するという体験も仮想空間内で行うことが出来るのではないかと考えました。しかし、このような体験を実現するためには二つの課題があります。一つはリアルタイムに変形する仮想粘土モデルの作成です。粘土のように変形する物体のCGについては様々な研究がされており、これらの研究の多くは視覚的な粘土らしさを表現するために粒子ベースモデルが利用されています。従来の粘土のように柔らかい物体を扱う粒子法は主に自然科学においてシミュレーションなどで用いられています。しかしながらいずれも物理モデルとしての精度に重点を置いており、その場で操作できるプログラムには使われません。本研究ではこのよりシンプルなモデルによって粘土特性の表現が可能であるかを検証しています。これによってリアルタイムにユーザーが操作できるモデルを実現しようとしています。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/nendo1.png" alt="写真1">
                            <figcaption>
                                写真1
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/nendo2.png" alt="写真2">
                            <figcaption>
                                写真2
                            </figcaption>
                        </figure>
                    </div>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        IRDMの計測による構築&nbsp;[2010-2012]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        IRDMを実変形物体の計測にに基づいて構築する手法について検討した。実物体にステップ状の力を作用してこれに対する変形の変化を記録する。空気噴射により力を作用し、ステレオカメラにより変形を計測する。これにより得られるステップ応答から、デコンボリューション処理によりインパルス応答を得る。実験では、ドーム形状と直方体形状のシリコンゴムでできた実物体に対する計測を行った。また、被験者を用いた実験により、実物体とモデルの類似性を検証した。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/kesoku1.jpg" alt="計測">
                            <figcaption>
                                計測
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/kesoku2.jpg" alt="モデルと実物体の比較">
                            <figcaption>
                                モデルと実物体の比較
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div>
                        <h4>
                            Video
                        </h4>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/kesoku1.m1v" download>
                                ドーム
                            </a>
                        </div>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/kesoku2.m1v" download>
                                直方体
                            </a>
                        </div>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/kesoku3.m1v" download>
                                変形の比較
                            </a>
                        </div>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Koichi&nbsp;Hirota,&nbsp;Kazuyoshi&nbsp;Tagawa:&nbsp;Acquisition&nbsp;of&nbsp;elastically&nbsp;deformable&nbsp;object&nbsp;model&nbsp;based&nbsp;on&nbsp;measurement;&nbsp;Proc.&nbsp;EuroHaptics&nbsp;2012,&nbsp;205-217,&nbsp;2012&nbsp;(poster)
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        インパルス応答変形モデル&nbsp;(IRDM)&nbsp;[2005-2006]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        弾性仮想物体の動的な変形に伴う力覚表現の実現手法について検討した。インパルス応答変形モデルでは、物体の力に伴う変形をインパルス力に対する時系列的な変形パターンとして記録する。インタラクションに伴う変形は、作用力とインパルス応答とのたたみ込みとして求められる。この手法の利点は、インタラクションに伴う力の計算がモデルの複雑さに直接的には依存しないこと、変形の計算はモデルの複雑さに対して１次のオーダーであることであり、仮想環境における実時間操作の実現に適している。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/irdm1.jpg" alt="IRDMの考え方">
                            <figcaption>
                                IRDMの考え方
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/irdm2.jpg" alt="実時間インタラクション">
                            <figcaption>
                                実時間インタラクション
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div>
                        <h4>
                            Video
                        </h4>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/irdm1.mpeg" download>
                                立方体モデル
                            </a>
                        </div>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/irdm2.mpeg" download>
                                ウサギモデル
                            </a>
                        </div>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Kazuyoshi&nbsp;Tagawa,&nbsp;Koichi&nbsp;Hirota,&nbsp;Michitaka&nbsp;Hirose:&nbsp;Impulse&nbsp;Response&nbsp;Deformation&nbsp;Model:&nbsp;an&nbsp;Approach&nbsp;to&nbsp;Haptic&nbsp;Interaction&nbsp;with&nbsp;Dynamically&nbsp;Deformable&nbsp;Object;&nbsp;Proc.&nbsp;Haptics&nbsp;Symposium&nbsp;2006,&nbsp;209-215,&nbsp;2006.3.
                        </li>
                        <li>
                            Kazuyoshi&nbsp;Tagawa,&nbsp;Koichi&nbsp;Hirota,&nbsp;Michitaka&nbsp;Hirose:&nbsp;Manipulation&nbsp;of&nbsp;Dynamically&nbsp;Deformable&nbsp;Object&nbsp;Using&nbsp;Impulse-Based&nbsp;Approach,&nbsp;Advances&nbsp;in&nbsp;Haptics,&nbsp;315-331,&nbsp;InTech,&nbsp;2010
                        </li>
                    </ol>
                </div>
                <br>
            </div>
            <div id="body_sensation_and_self_awareness" class="content_main">
                <!--コンテンツタイトル-->
                <span class="content_name">
                    身体感覚と自己認識
                </span>
                <hr>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        VRツイスター&nbsp;[2017-2021]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        昨今、VR 空間内を実際に自由に歩き回ってプレイするスタイルのゲームが多く見られるようになりました。こうしたゲーム中のアバタは、自分の分身としてに現実の全身の動作に連動して動くことがほとんどです。一方で先行研究より、「アバタの外見につられて陽気に楽器を弾くようになる」「アバタの外見によって人前でスピーチする際の緊張状態が軽減される」などVR空間内のアバタの外見が現実の身体動作に影響することが分かっています。そこで、全身を使ったVRゲームにおいても同様に、アバタの外見が現実の身体動作に作用するのではないかと考えました。本研究では、ゲームプレイにおいて身体バランスや全身の使い方を特に意識する必要があるツイスターゲームに着目し、モーションキャプチャを用いてVR 上でツイスターゲームを行う際に、自他プレイヤーのアバタの外見がゲームプレイに与える影響について検証を進めています。<br>
                        ※この研究は科研費基盤(B)JP19H04230の支援を受けて実施された。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/twister1.png" alt="写真1">
                            <figcaption>
                                写真1
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/twister1.png" alt="写真2">
                            <figcaption>
                                写真2
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div>
                        <h4>
                            Video
                        </h4>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/twister1.mp4" download>
                                VR&nbsp;Twister&nbsp;システム
                            </a>
                        </div>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/twister2.mp4" download>
                                体験の様子
                            </a>
                        </div>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            長野&nbsp;瑞生,&nbsp;櫻井&nbsp;翔,&nbsp;野嶋&nbsp;琢也,&nbsp;広田&nbsp;光一:&nbsp;オフライン運動観察におけるVRアバターの外見や動作が自己身体認識に及ぼす影響;&nbsp;日本VR学会論文誌,&nbsp;23(3),&nbsp;169-177,&nbsp;2018
                        </li>
                        <li>
                            Sho&nbsp;Sakurai,&nbsp;Takumi&nbsp;Goto,&nbsp;Takuya&nbsp;Nojima,&nbsp;Koichi&nbsp;Hirota:&nbsp;Effect&nbsp;of&nbsp;the&nbsp;Opponent’s&nbsp;Appearance&nbsp;on&nbsp;Interpersonal&nbsp;Cognition&nbsp;that&nbsp;Affects&nbsp;User-to-User&nbsp;Relationship&nbsp;in&nbsp;Virtual&nbsp;Whole-Body&nbsp;Interaction;&nbsp;Journal&nbsp;of&nbsp;Robotics&nbsp;and&nbsp;Mechatronics&nbsp;33(5),&nbsp;1029-1042,&nbsp;2021
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        眼間距離及びアバタの体格がアバタの形状認識と身体所有感に与える影響&nbsp;[2020- ]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        VR空間で身体の代替であるアバタの形状はVRコンテンツの文脈によって人間の体格と異なることが好ましい場合があります。一方で、自分の実際の身体と体格の異なるアバタを用いることは身体所有感の低下を招く可能性があり、体験の質に影響を与えることが考えられます。本研究ではVR空間で眼間距離（HMDに出力する2つのカメラの間隔）とアバタの身体部位のサイズがそれぞれVR空間内のオブジェクトに対する形状知覚に影響を与えることに着目しました。そこで、眼間距離とアバタの腕及び脚の長さが、腕と脚に対する形状知覚と身体所有感に与える影響について検証を進めています。<br>
                        ※この研究は科研費基盤(B)JP19H04230，及び科研費基盤(S)JP19H05661の支援を受けて実施された。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/oka202111281.png" alt="アバタの条件">
                            <figcaption>
                                アバタの条件
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/oka202111282.png" alt="腕も脚も普通のアバタ">
                            <figcaption>
                                腕も脚も普通のアバタ
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/oka202111283.png" alt="腕も脚も長いアバタ">
                            <figcaption>
                                腕も脚も長いアバタ
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Tokio&nbsp;Oka,&nbsp;Takumi&nbsp;Goto,&nbsp;Nobuhito&nbsp;Kimura,&nbsp;Sho&nbsp;Sakurai,&nbsp;Takuya&nbsp;Nojima,&nbsp;Koichi&nbsp;Hirota:&nbsp;Effects&nbsp;of&nbsp;Interpupillary&nbsp;Distance&nbsp;and&nbsp;Visual&nbsp;Avatar’s&nbsp;Shape&nbsp;on&nbsp;the&nbsp;Perception&nbsp;of&nbsp;the&nbsp;Avatar’s&nbsp;Shape&nbsp;and&nbsp;the&nbsp;Sense&nbsp;of&nbsp;Ownership;&nbsp;In:&nbsp;HCI&nbsp;International&nbsp;2021,&nbsp;2021
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        アバタの外見が動作および心理に与える影響&nbsp;[2019-]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/takei_avatar.png" alt="怪獣アバタと人アバタ">
                            <figcaption>
                                怪獣アバタと人アバタ
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div>
                        <h4>
                            Video
                        </h4>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/takei_avatar.mp4" download>
                                怪獣になって街を壊してみると…
                            </a>
                        </div>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            櫻井翔,&nbsp;武井友里恵,&nbsp;野島琢也,&nbsp;広田光一:&nbsp;怪獣アバタを用いたバーチャル破壊体験による非主張性軽減手法の検討;&nbsp;第25回日本VR学会大会予稿集,&nbsp;2A2-4,&nbsp;2020
                        </li>
                        <li>
                            櫻井翔,&nbsp;帆山遼,&nbsp;野島琢也,&nbsp;広田光一:&nbsp;客体化された自己としてのアバタの外見がアバタへの自他判断と行動評価に与える影響;&nbsp;第25回日本VR学会大会予稿集,&nbsp;2A2-3,&nbsp;2020
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        視覚的特徴の自己身体感覚への影響&nbsp;[2016- ]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        運動の学習においては、しばしは学習者の運動を撮影して見直したり、これをベテランのものと比較したりして、学習者の運動の問題点を見つけ出すことが試みられる。しかしながら、学習者が自身の運動を観察する場合、映像の中の自身にある種の自己身体感覚が生じ、これにより自己評価バイアスが生じる懸念がある。このバイアスは、一般には評価が甘くなる方向に作用する。本研究では、自己身体感覚の生成に影響を与えると考えられる外見的特徴を変化させることで自己身体感覚を薄れさせ、評価の水準を向上できるのではないかと考えた。
                        ※この研究は科研費基盤(A)26240029(代表者:首都大 池井寧)の支援を受けて実施されている。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img class="content_image_horizontal" src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/body-sens1.png" alt="外見的特徴の違い">
                            <figcaption>
                                外見的特徴の違い
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div>
                        <h4>
                            Video
                        </h4>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/radio1.mp4" download>
                                自身の動きを客観的に見る
                            </a>
                        </div>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/radio2.mp4" download>
                                実験の様子(ラジオ体操)
                            </a>
                        </div>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            長野,&nbsp;広田,&nbsp;野嶋,&nbsp;北崎,&nbsp;池井:&nbsp;歩行動作における身体感覚と視覚情報の不一致による違和感の評価;&nbsp;VR学研法,&nbsp;21，VRUR-1,&nbsp;27-28,&nbsp;2016.6.
                        </li>
                    </ol>
                </div>
                <br>
            </div>
            <div id="emotion_and_affect" class="content_main">
                <!--コンテンツタイトル-->
                <span class="content_name">
                    感情と情動
                </span>
                <hr>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        疑似的緊張状態がゲームプレイに及ぼす影響の評価&nbsp;[2017- ]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        この研究は、市場で売られてるゲームの難易度はすべてゲーム制作陣が設定した数値に左右されているのが面白くなく、じゃあプレイヤー側の状態変えることで難易度に干渉してみようぜという試みから始まったものです。心理学の分野では、外部からの刺激によって感情が生起されるとき、身体反応が先に起こりその後で感情を自覚するとする学説（ジェームズ・ランゲ説）があります。「悲しいから泣くのではなく、悲しいから泣く」という考え方です。また、同じ身体反応でもその原因によって生起する感情は異なるとする学説（シャクターの情動二要因説）も知られています。悲しい知らせによって泣いたなら「悲しみ」の感情が、嬉しさの余り泣いたなら「喜び」の感情が生じます。本研究では、この2つの学説をもとにして、ゲームをしている最中に空気パックでこっそり胸部を締め付けて、緊張した時の息苦しさを再現してやります。すると体は緊張感を覚えますが、脳みそがその原因をゲームだと勘違いすれば、「自分は今ゲームに緊張してるんだ！」と勘違いしてくれます。過去の研究で、感情の変化は今自分がやっている作業への主観的な難易度に影響を及ぼす可能性が示唆されています。よってゲームに対して緊張感を持たせれば、「内容が一切変わっていないゲームに対し、いつもより難しいと感じさせる」ことが可能になるのです！
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/game1.jpg" alt="写真1">
                            <figcaption>
                                写真1
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/game2.jpg" alt="写真2">
                            <figcaption>
                                写真2
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/game3.jpg" alt="写真3">
                            <figcaption>
                                写真3
                            </figcaption>
                        </figure>
                    </div>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        時計を用いた作業効率向上&nbsp;[2017- ]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        作業の締め切り前などに時計の進みが速くなったように見える経験をしたことがあるだろう。これは認知負荷の一種であるタイムプレッシャーによるものである。タイムプレッシャーは、ある問題を解決するために必要であると見積もられる時間と実際に与えられた時間の比率によって決定される。タイムプレッシャー下では、意思決定のための情報処理に影響が生じ、意思決定に伴って次の行動を起こすまでの時間が短くなるという報告がある。また、タスクパフォーマンスや生産性が向上することが示されている。そのため、このタイムプレッシャーを疑似的に起こすことができれば、作業効率を向上することができると考えられる。我々は、タイムプレッシャーを生じさせるために、時間感覚に変化を与えうる要因として時計に着目した。時計は、本来基準のない時間の共通尺度として用いられるため、時計の見かけの表示時間が多くの人の時間感覚に影響すると考えられる。本研究では、作業環境に存在する時計が示す時間の経過速度の制御により作業効率を向上する手法を提案する。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/watch1.png" alt="写真1">
                            <figcaption>
                                写真1
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/watch2.png" alt="写真2">
                            <figcaption>
                                写真2
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            吉永&nbsp;亮佑,&nbsp;櫻井&nbsp;翔,&nbsp;伴&nbsp;祐樹,&nbsp;野嶋&nbsp;琢也,&nbsp;広田&nbsp;光一:&nbsp;時間的制約下での創造的作業における時計の認識調査;&nbsp;日本VR学会第22回大会予稿集,&nbsp;3A2-01,&nbsp;2017
                        </li>
                    </ol>
                </div>
                <br>
            </div>
            <div id="sense_of_walking" class="content_main">
                <!--コンテンツタイトル-->
                <span class="content_name">
                    歩行感覚
                </span>
                <hr>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        三次元空間歩行体験&nbsp;[2017- ]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        座る状態でHMDによって提示されるバーチャル空間を実際に歩いているかのような体験を目指す、また三次元空間を自由に歩き回るという人間が本来できない体験を挑戦する研究です。アプローチとしては腕の動きをトラッキングし、第一人称のアバターの歩行アニメーションを制御する同時に、脚部へ振動刺激を提示することで、より能動的な歩行体験を試みます。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/walk1.png" alt="写真1">
                            <figcaption>
                                写真1
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/walk2.png" alt="写真2">
                            <figcaption>
                                写真2
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Nariaki&nbsp;Sugamoto,&nbsp;Yusuke&nbsp;Ujitoko,&nbsp;Sho&nbsp;Sakurai:&nbsp;Inclination&nbsp;Manipulator&nbsp;:&nbsp;Pitch&nbsp;Redirected&nbsp;Walking&nbsp;using&nbsp;Haptic&nbsp;Cues&nbsp;SessionEmerging&nbsp;Technologies&nbsp;Presentations;&nbsp;SIGGRAPH&nbsp;Asia&nbsp;2019&nbsp;Emerging&nbsp;Technologies.
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        身体運動の認識が主体感に与える影響&nbsp;[2016-2018]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        歩行追体験とは、身体に対して歩行時と類似の運動を与えることで、あたかも自身が歩行しているかのような感覚を与えることである。その実現における問題の一つは、追体験者に、外部から与えられる受動的な歩行運動を、自身の意思による能動的な運動であるかのように感じさせることである。行為主体感は、通常は能動的運動に対して生じると考えられるが、歩行は多分に自動的で無意識的に行うことができることから、能動性がない条件でも追体験者の意識を適切な状態に保てば、能動的な感覚を与えることができるのではないかと考えている。現在、このための基礎的な検討を進めている。<br>
                        ※この研究は科研費基盤(A)26240029(代表者:首都大 池井寧)の支援を受けて実施されている。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/walk-device.jpg" alt="歩行運動提示デバイス">
                            <figcaption>
                                歩行運動提示デバイス
                            </figcaption>
                        </figure>
                    </div>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        歩行の記録・再生&nbsp;[2014-2018]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        歩行の動作とその際の生じる感覚情報を計測・伝送し別の人に提示することで、歩行を追体験することを検討する。歩行の速さや状態だけでなく、実体験者の体格や歩行の特徴を追体験者に伝えることを狙う。<br>
                        ※この研究は首都大学東京 池井研究室と共同で実施しています。<br>
                        ※この研究は総務省SCORPによる受託研究14120319(代表者:首都大 池井寧)の一部として実施されている。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/walk-sens.jpg" alt="計測システム">
                            <figcaption>
                                計測システム
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/hoko_disp.jpg" alt="提示システム">
                            <figcaption>
                                提示システム
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div>
                        <h4>
                            Video
                        </h4>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/walk-motion.mp4" download>
                                歩行動作（加速度センサ）
                            </a>
                        </div>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/walk-mocap.mov" download>
                                歩行動作の計測
                            </a>
                        </div>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Kohei&nbsp;Ichihara,&nbsp;Koichi&nbsp;Hirota,&nbsp;Yasushi&nbsp;Ikei,&nbsp;Michiteru&nbsp;Kitazaki:&nbsp;Presentation&nbsp;method&nbsp;of&nbsp;walking&nbsp;sensation&nbsp;based&nbsp;on&nbsp;walking&nbsp;behavior&nbsp;measurement&nbsp;with&nbsp;inertial&nbsp;sensors&nbsp;and&nbsp;pressure&nbsp;sensors;&nbsp;Proc.HCII2015,&nbsp;LNCS&nbsp;9172,&nbsp;374-385,&nbsp;2015.8
                        </li>
                        <li>
                            楊,&nbsp;広田,&nbsp;野嶋,&nbsp;北崎,&nbsp;池井:&nbsp;加速度センサーを用いた歩行モーションの計測に関する研究;&nbsp;VR学研法,&nbsp;21，VRUR-1,&nbsp;20-22,&nbsp;2016.6.
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        高密度足裏圧覚提示デバイス&nbsp;[2015-2016]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        足裏に圧覚を提示するためのデバイづの開発を行った。足裏の触覚は、手には及ばないものの、比較的高い分解能を持っているとされる。また、足が体重を支えることから、比較的大きな作用力を知覚することができる。本研究ではこのような特性を持つ足裏に対して圧覚を提示するデバイスを設計・試作した。比較的大きな力を発生できるアクチュエータを高密度に配置する必要があることから、ここではエアシリンダを利用した。空気圧を電空レギュレータにより制御し、プラスチック管と金属軸から構成されるシリンダアレイに供給する。10mm間隔の最密充填配置で128点の力を独立に制御できるデバイスを試作した。<br>
                        ※この研究は総務省SCORPによる受託研究14120319(代表者:首都大 池井寧)の一部として実施されている。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/foot-device1.jpg" alt="高密度圧覚提示デバイス">
                            <figcaption>
                                高密度圧覚提示デバイス
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/foot-device2.jpg" alt="圧覚提示の様子">
                            <figcaption>
                                圧覚提示の様子
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div>
                        <h4>
                            Video
                        </h4>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/foot-device.mp4" download>
                                圧覚提示デバイス
                            </a>
                        </div>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            岡野,&nbsp;日岐,&nbsp;広田,&nbsp;野嶋,&nbsp;北崎,&nbsp;池井:&nbsp;空気圧駆動型デバイスを用いた足裏への触覚提示による物体の位置認識;&nbsp;VR学会第21大会予稿集,&nbsp;11A-05,&nbsp;2016.9.
                        </li>
                        <li>
                            日岐,&nbsp;岡野,&nbsp;広田,&nbsp;野嶋,&nbsp;北崎,&nbsp;池井:&nbsp;足裏触覚提示による位置認識精度の評価;&nbsp;VR学研法,&nbsp;21，VRUR-1,&nbsp;23-26,&nbsp;2016.6.
                        </li>
                    </ol>
                </div>
                <br>
            </div>
            <div id="haptic_interface" class="content_main">
                <!--コンテンツタイトル-->
                <span class="content_name">
                    触覚インタフェース
                </span>
                <hr>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        唇触覚デバイスの開発&nbsp;[2015-2016]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        唇は触覚的に最も敏感な領域の一つである。とりわけ空間分解能が高く、指先に近い弁別閾を示すことが知られている。したがって、触覚情報提示の対象として唇を利用することで、情報的密度の高い触覚情報伝達が可能であると期待される。本課題では、ピエゾ振動子による高密度な振動刺激提示装置を開発している。予備的実装として、2mmピッチで16点の刺激が可能なデバイスを開発し、これを用いて振動刺激に対する二点弁別特性などの調査を行っている。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/kuchi1.jpeg" alt="デバイスの実装">
                            <figcaption>
                                デバイスの実装
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/kuchi2.jpeg" alt="実験の様子">
                            <figcaption>
                                実験の様子
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            筒井&nbsp;悠平,&nbsp;広田&nbsp;光一,&nbsp;野嶋&nbsp;琢也:&nbsp;圧電バイモルフを用いた口唇のための高解像度触覚ディスプレイ;&nbsp;日本VR学会研究報告,&nbsp;HDC16,&nbsp;No.12,&nbsp;2015.11.
                        </li>
                        <li>
                            Yuhei&nbsp;Tsutsui,&nbsp;Koichi&nbsp;Hirota&nbsp;,&nbsp;Takuya&nbsp;Nojima,&nbsp;Yasushi&nbsp;Ikei:&nbsp;High-Resolution&nbsp;Tactile&nbsp;Display&nbsp;for&nbsp;Lips;&nbsp;Proc.&nbsp;HCII2016&nbsp;(LNCS&nbsp;9735),&nbsp;357-366,&nbsp;2016.
                        </li>
                        <li>
                            筒井,&nbsp;広田,&nbsp;野嶋:&nbsp;口唇触覚ディスプレイ;&nbsp;VR学会第21大会予稿集,&nbsp;34A-02,&nbsp;2016.9.
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        プロトタイプ4:&nbsp;デバイスと制御&nbsp;[2013- ]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        慣性力の提示は重心の移動の提示と等価である。本研究では、力出力の特性改善と重心移動範囲の拡大を目的として新たなデバイスを開発した。現在、このデバイスによる提示と実物との比較の実験を行っている。具体的には、剛物体の入った箱、水の入ったボトルについて、これと同様の状況をデバイスにより提示し、内容物の重さの弁別特性について、実物とデバイスとで評価している。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/furu4-1.jpg" alt="デバイス">
                            <figcaption>
                                デバイス
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/furu4-2.jpg" alt="「振ってみる」操作">
                            <figcaption>
                                「振ってみる」操作
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div>
                        <h4>
                            Video
                        </h4>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/furu4.wmv" download>
                                デバイス
                            </a>
                        </div>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Takeshi&nbsp;Yamamoto,&nbsp;Koichi&nbsp;Hirota:&nbsp;Device&nbsp;for&nbsp;Estimating&nbsp;Weight&nbsp;and&nbsp;Material&nbsp;of&nbsp;Contents&nbsp;of&nbsp;Boxes&nbsp;by&nbsp;Shaking;&nbsp;Proc.&nbsp;EuroHaptics&nbsp;2014,&nbsp;(in&nbsp;Press),&nbsp;2014
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        プロトタイプ3:&nbsp;内容物の推定(2)&nbsp;[2012-2013]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        よりコンパクトな機構で慣性力を提示するデバイスを試作した。箱の中に剛物体が入っているモデルを用いて、中身の重さ、箱と中身の衝突の反発係数および運動の摩擦係数などを変化させ、被験者に弁別させる実験を行った。その結果、パラメータの変化の認識が可能であることが確認された。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/shake1.jpg" alt="デバイス">
                            <figcaption>
                                デバイス
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/shake2.jpg" alt="モデルパラメータの弁別">
                            <figcaption>
                                モデルパラメータの弁別
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Yasuhiro&nbsp;Tanaka,&nbsp;Koichi&nbsp;Hirota:&nbsp;Shaking&nbsp;a&nbsp;box&nbsp;to&nbsp;estimate&nbsp;the&nbsp;property&nbsp;of&nbsp;content;&nbsp;Proc.&nbsp;EuroHaptics&nbsp;2013,&nbsp;564-576,&nbsp;2013&nbsp;(poster)
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        プロトタイプ2:&nbsp;慣性力の提示&nbsp;[2006-2008]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        「振ってみる」インタラクションの基本は、ユーザが箱に与える運動とそれに伴う慣性力との関係性にある。そこで、慣性力を提示するデバイスとその制御システムについて検討した。このプロトタイプでは、振り小型の機構により慣性力を発生する。箱に作用する外力（手からの力）の推定、VRモデルに基づく箱の加速度の計算、これを実現するトルクの計算からなる制御ループにより、インタラクションが可能になる。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/furu1.jpg" alt="デバイス">
                            <figcaption>
                                デバイス
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/furu2.jpg" alt="制御系">
                            <figcaption>
                                制御系
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div>
                        <h4>
                            Video
                        </h4>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/furu1.m1v" download>
                                Without Control
                            </a>
                        </div>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/furu2.m1v" download>
                                Rigid Body
                            </a>
                        </div>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/furu3.m1v" download>
                                Box with an Object Inside
                            </a>
                        </div>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            K.&nbsp;Hirota,&nbsp;Y.&nbsp;Sekiguchi:&nbsp;Inertial&nbsp;force&nbsp;display&nbsp;-&nbsp;concept&nbsp;and&nbsp;implementation;&nbsp;Proc.&nbsp;ISUC2008,&nbsp;281-284,&nbsp;2008
                        </li>
                        <li>
                            Koichi&nbsp;Hirota,&nbsp;Yuichiro&nbsp;Sekiguchi:&nbsp;Transmission&nbsp;of&nbsp;Information&nbsp;Through&nbsp;Haptic&nbsp;Interaction;&nbsp;Proc.&nbsp;HCII&nbsp;2009,&nbsp;LNCS&nbsp;5622,&nbsp;313-317,&nbsp;2009
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        プロトタイプ1:&nbsp;内容物の推定(1)&nbsp;[2002-2003]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        箱やビンを振ると中身の量や性質がわかる。このようなインタラクションをVRとして実現するデバイスについて検討し、プロトタイプとして、小物体の入った箱を仮想的に実現するデバイスを試作した。ユーザが箱を 振る動作を加速度センサにより計測し、これをもとに仮想の小物体と箱との衝 突をシユレートして、ソレノイドアクチュエータ（電磁石）によって衝撃を提示する。被験者を用いた評価により、現実に近い表現が可能であることが確認された。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/futte1.jpg" alt="アイディア">
                            <figcaption>
                                アイディア
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/futte2.jpg" alt="デバイス">
                            <figcaption>
                                デバイス
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div>
                        <h4>
                            Video
                        </h4>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/futte1.mpeg" download>
                                デバイスの操作の様子
                            </a>
                        </div>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Y.Sekiguchi,&nbsp;K.Hirota,&nbsp;M.Hirose:&nbsp;Haptic&nbsp;Interface&nbsp;Using&nbsp;Estimation&nbsp;of&nbsp;Box&nbsp;Contents&nbsp;Metaphor;&nbsp;Proc.&nbsp;ICAT2003,&nbsp;197-202,&nbsp;2003.12.
                        </li>
                    </ol>
                </div>
                <br>
            </div>
            <div id="other_research" class="content_main">
                <!--コンテンツタイトル-->
                <span class="content_name">
                    その他
                </span>
                <hr>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        心エコーシミュレータの開発&nbsp;[2015- ]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        心臓における超音波検査（心エコー検査）は心臓の大きさ、形、心臓の壁の厚さや動き方、血流などを可視化する検査手法です。心臓の動きをリアルタイムで計測可能な検査手法であり、使用される超音波は人体に無害とされ、痛みを生じることもないため、心臓の健康状態を確認するうえで最も一般的な検査法の一つといえます。しかし、超音波検査において心臓の観察は、大きく収縮運動を行うことや、血流を読み取る力が要求されるため、より高い症例など知識の習熟が必要となります。心エコーにおける症例などの学習において、より多くの症例を学習できることは大きな重要性を持っています。本研究では、心臓の形状データから心エコー検査で得られるような断面画像の生成を行うシステムの開発を行っています。脈拍を行う心臓の形状データと人体における超音波の伝播特性から、リアルタイムでのシミュレート画像生成を目指します。心臓の形状データを基としたシミュレータの開発は、計測された心臓の形状データやシミュレートにより再現された心臓のデータから心エコー検査の再現が可能となります。このことは、より多くの症例を学習することを可能にします。<br>
                        ※東京大学大学院新領域創成科学研究科人間環境学専攻久田研究室
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/echo1.jpg" alt="写真1">
                            <figcaption>
                                写真1
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/echo2.png" alt="写真2">
                            <figcaption>
                                写真2
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            田村&nbsp;莞爾,&nbsp;広田&nbsp;光一,&nbsp;野島&nbsp;琢也,&nbsp;杉浦&nbsp;清了,&nbsp;久田&nbsp;俊明:&nbsp;心エコーシミュレータにおけるシミュレート画像生成アルゴリズムの検討;&nbsp;日本VR学会第22回大会予稿集,&nbsp;1E2-04,&nbsp;2017
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        風向の補間提示&nbsp;[2012-2013]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        五感シアターで様々な方向からの風を提示する手法を開発した。シアター環境では風を生成するファンはをスクリーンや他の感覚提示デバイスを避けて配置する必要がある。すなわち、離散的に配置されたファンにより補間的に風向の連続な変化を生成する必要がある。本研究では、２つのファンの強度に対する風向と風速のマップを作成し、これを逆参照することで、任意の風向と風速を提示する手法を提案する。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/kaze1.jpg" alt="方向と速度のマップ">
                            <figcaption>
                                方向と速度のマップ
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/kaze2.jpg" alt="風向の認識特性">
                            <figcaption>
                                風向の認識特性
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Koichi&nbsp;Hirota,&nbsp;Yoko&nbsp;Ito,&nbsp;Tomohiro&nbsp;Amemiya,&nbsp;Yasushi&nbsp;Ikei:&nbsp;Generation&nbsp;of&nbsp;Directional&nbsp;Wind&nbsp;by&nbsp;Colliding&nbsp;Airflows;&nbsp;Proc.&nbsp;WHC&nbsp;2013,&nbsp;509-514,&nbsp;2013
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        つり革による前庭感覚提示&nbsp;[2012-2013]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        バスや電車のつり革は乗り物の揺れに対して人が立つことを支援する道具であるが、つり革はまた、乗り物の動きを人に伝えるインタフェースと考えることもできる。本研究では、床とつり革の動きにより身体の空間運動の感覚を提示する新たなモーションベースの開発を試みた。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/tsuri1.jpg" alt="つり革デバイス">
                            <figcaption>
                                つり革デバイス
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/tsuri2.jpg" alt="実装">
                            <figcaption>
                                実装
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div>
                        <h4>
                            Video
                        </h4>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/tsuri.wmv" download>
                                プロトタイプ
                            </a>
                        </div>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Takashi&nbsp;Sasaki,&nbsp;Koichi&nbsp;Hirota,&nbsp;Tomohiro&nbsp;Amemiya,&nbsp;Yasushi&nbsp;Ikei:&nbsp;Train&nbsp;Ride&nbsp;Simulation&nbsp;using&nbsp;Assist&nbsp;Strap&nbsp;Device;&nbsp;Proc.&nbsp;HCII2013,&nbsp;LNCS&nbsp;8017,&nbsp;189-197,&nbsp;2013
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        ノンバーバル情報による感情伝達&nbsp;[2010-2012]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        人の息遣いや接触による非言語的な情報の伝達を可能にするシステムの提案と評価を行った。風速計により計測された呼吸情報を伝達しノズルによる気流として提示することで、感情状態の伝達が支援されることを確認した。また、平板上での力の大きさと作用点を計測し、これをロボットアームを介して背中の圧迫として提示することで、背中をなでるのに類似する感情制御の効果が示唆された。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/kanjo1.jpg" alt="呼吸伝達デバイス">
                            <figcaption>
                                呼吸伝達デバイス
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/kanjo2.jpg" alt="なでる動作の伝達デバイス">
                            <figcaption>
                                なでる動作の伝達デバイス
                            </figcaption>
                        </figure>
                    </div>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        五感コンテンツのインタラクティブ編集環境&nbsp;[2010-2011]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        五感シアターのためのコンテンツを制作する環境を開発した。シアターのデバイスをMIDIインタフェースにより制御できるようにし、音楽用のキーボードおよびシーケンスソフトと接続することで、実時間での感覚情報提示の記録と再生を行う。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/content1.jpg" alt="シアター環境に配置されたデバイス">
                            <figcaption>
                                シアター環境に配置されたデバイス
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/content2.jpg" alt="MIDIシーケンサによる記録・編集・再生">
                            <figcaption>
                                MIDIシーケンサによる記録・編集・再生
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Koichi&nbsp;Hirota,&nbsp;Seichiro&nbsp;Ebisawa,&nbsp;Tomohiro&nbsp;Amemiya,&nbsp;Yasushi&nbsp;Ikei:&nbsp;A&nbsp;theaterfor&nbsp;viewing&nbsp;and&nbsp;editing&nbsp;multi-sensory&nbsp;content;&nbsp;Proc.&nbsp;ISVRI&nbsp;2011,&nbsp;237-242,&nbsp;2011
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        嗅覚の提示&nbsp;[2009-2010]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        シアター環境において匂いを提示するデバイスを開発した。匂いの素をビンの中で気化させ、このビンに空気を送り込むことで、気化した臭気を放出する。最大で15種類の異なる匂いを混合して提示することのできるデバイスを試作した。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/nioi1.jpg" alt="嗅覚ディスプレイ">
                            <figcaption>
                                嗅覚ディスプレイ
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/nioi2.jpg" alt="濃度の制御">
                            <figcaption>
                                濃度の制御
                            </figcaption>
                        </figure>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Koichi&nbsp;Hirota,&nbsp;Yasushi&nbsp;Ikei,&nbsp;Tomohiro&nbsp;Amemiya:&nbsp;Olfactory&nbsp;Display&nbsp;for&nbsp;Multi-sensory&nbsp;Theater;&nbsp;Proc.&nbsp;ASIAGRAPH&nbsp;2010,&nbsp;24-28,&nbsp;2010
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        全周多視点ディスプレイ&nbsp;[2005-2008]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        視点の位置によって異なる映像を提示することのできるディスプレイを多視点 ディスプレイと呼ぶ。このようなディスプレイのひとつの実現方法として、平面ディスプレイパネルを回転させてその方向に応じた映像を時分割で提示する 手法を提案している。ディスプレイパネルに視野を狭めるフィルターを装着す ることで、パネルが視点方向を向いていない状態での映像が視点から見えないようにする。等身大の人物像を提示するために大型のプラズマディスプレイによるプロトタイプを構築した。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/kuru1.jpg" alt="デバイス">
                            <figcaption>
                                デバイス
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/kuru2.jpg" alt="提示される映像">
                            <figcaption>
                                提示される映像
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div>
                        <h4>
                            Video
                        </h4>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/kuru1.mpeg" download>
                                System&nbsp;Structure
                            </a>
                        </div>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/kuru2.mpeg" download>
                                Start&nbsp;Up
                            </a>
                        </div>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/kuru3.mpeg" download>
                                Motion&nbsp;of&nbsp;Viewing&nbsp;Point
                            </a>
                        </div>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            K.Hirota,&nbsp;K.Tagawa,&nbsp;Y.Suzuki:&nbsp;Automultiscopic&nbsp;display&nbsp;by&nbsp;revolving&nbsp;flat-panel&nbsp;displays;&nbsp;Proc.&nbsp;Virtual&nbsp;Reality&nbsp;2008,&nbsp;161-168,&nbsp;2008.3.
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        ウェアラブル聴覚インタフェース&nbsp;[2001-2007]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        ウェアラブルのための聴覚インタフェースに関する検討を行っている。頭部伝達関数（HRTF）による方向定 位を利用することで、ポインティング操作の実現、情報の選択的取得特性に関する検討、人の誘導に関する試みなどを行い、その特性を明らかにした。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/wsd2.jpg" alt="デバイス">
                            <figcaption>
                                デバイス
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/wsd3.jpg" alt="操作の様子">
                            <figcaption>
                                操作の様子
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div>
                        <h4>
                            Video
                        </h4>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/wsd1.mpeg" download>
                                Item&nbsp;Sellection&nbsp;Task
                            </a>
                        </div>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            K.Hirota,&nbsp;M.Hirose:&nbsp;An&nbsp;Implementation&nbsp;of&nbsp;Wearable&nbsp;Auditory&nbsp;Interface;&nbsp;Proc.&nbsp;MOVIC&nbsp;2002,&nbsp;570-575,&nbsp;2002.8.
                        </li>
                        <li>
                            K.&nbsp;Hirota,&nbsp;Y.&nbsp;Watanabe,&nbsp;Y.&nbsp;Ikei:&nbsp;Menu&nbsp;Selection&nbsp;Using&nbsp;Auditory&nbsp;Interface;&nbsp;Proc.&nbsp;HCII2007,&nbsp;70-75,&nbsp;2007.7.
                        </li>
                    </ol>
                </div>
                <br>
                <div>
                    <!--コンテンツサブタイトル-->
                    <div class="other_content_subtitle">
                        インタラクティブ空間走査型ディスプレイ&nbsp;[2005-2007]
                    </div>
                    <!--コンテンツ内容-->
                    <div class="other_content_text">
                        インタラクティブに3次元ボリュームデータを表示するディスプレイを開発した。ユーザが操作するスクリーンパネルの位置・姿勢をセンサにより計測し、そのパネルの位置での3次元データの断面を生成・投影する。この仕組みを比較的早い動きにまで適用することで、ユーザがスクリーンを「ぱたぱた」と動かした場合に、残像効果による3次元の映像の提示がある程度可能であることを確認した。
                    </div>
                    <!--画像-->
                    <div class="other_contents_flex_wrap">
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/pata1.jpg" alt="ユーザによる操作">
                            <figcaption>
                                ユーザによる操作
                            </figcaption>
                        </figure>
                        <figure class="other_content_figure">
                            <img src="D:/ドキュメント/GitClone/HirotaLabWeb/ResearchImage/pata2.jpg" alt="3Dモデルの提示">
                            <figcaption>
                                3Dモデルの提示
                            </figcaption>
                        </figure>
                    </div>
                    <!--動画-->
                    <div>
                        <h4>
                            Video
                        </h4>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/pata1.mpeg" download>
                                立方体
                            </a>
                        </div>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/pata2.mpeg" download>
                                球
                            </a>
                        </div>
                        <div>
                            <a href="http://www.hirota-lab.sumomo.ne.jp/research/movie/pata3.mpeg" download>
                                CT画像
                            </a>
                        </div>
                    </div>
                    <!--参考文献-->
                    <ol class="other_content_reference">
                        <li>
                            Koichi&nbsp;Hirota,&nbsp;Yuya&nbsp;Saeki:Cross-section&nbsp;Projector:&nbsp;Interactive&nbsp;and&nbsp;Intuitive&nbsp;Presentation&nbsp;of&nbsp;3D&nbsp;Volume&nbsp;Data&nbsp;using&nbsp;a&nbsp;Handheld&nbsp;Screen;&nbsp;Proc.&nbsp;3DUI2007,&nbsp;57-63,&nbsp;2007.3.
                        </li>
                    </ol>
                </div>
                <br>
            </div>
        </div>
        <footer>
            <div id="in_footer">
                <div>
                    copyright (c) 2021 Hirota's Lab. all rights reserved.
                </div>
            </div>
        </footer>
        <div id="to_top">
            <a class="to_top_a" href="#title" target="_self">
                Topへ
            </a>
        </div>
    </body>
</html>